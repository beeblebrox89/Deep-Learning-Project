{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Tests on Ensemble learning methods"
      ],
      "metadata": {
        "id": "z0K50IAR5gmQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "prwlyqfVZbld",
        "outputId": "94fe7959-4659-477d-f8dd-6fe481009c11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/kaggle/input/bone-break-classification-image-dataset/Bone Break Classification/Bone Break Classification/Avulsion fracture\n",
            "/kaggle/input/bone-break-classification-image-dataset/Bone Break Classification/Bone Break Classification/Spiral Fracture\n",
            "/kaggle/input/bone-break-classification-image-dataset/Bone Break Classification/Bone Break Classification/Impacted fracture\n",
            "/kaggle/input/bone-break-classification-image-dataset/Bone Break Classification/Bone Break Classification/Hairline Fracture\n",
            "/kaggle/input/bone-break-classification-image-dataset/Bone Break Classification/Bone Break Classification/Greenstick fracture\n",
            "/kaggle/input/bone-break-classification-image-dataset/Bone Break Classification/Bone Break Classification/Pathological fracture\n",
            "/kaggle/input/bone-break-classification-image-dataset/Bone Break Classification/Bone Break Classification/Oblique fracture\n",
            "/kaggle/input/bone-break-classification-image-dataset/Bone Break Classification/Bone Break Classification/Fracture Dislocation\n",
            "/kaggle/input/bone-break-classification-image-dataset/Bone Break Classification/Bone Break Classification/Longitudinal fracture\n",
            "/kaggle/input/bone-break-classification-image-dataset/Bone Break Classification/Bone Break Classification/Comminuted fracture\n",
            "                                                path             target  split\n",
            "0  /kaggle/input/bone-break-classification-image-...  Avulsion fracture  Train\n",
            "1  /kaggle/input/bone-break-classification-image-...  Avulsion fracture  Train\n",
            "2  /kaggle/input/bone-break-classification-image-...  Avulsion fracture  Train\n",
            "3  /kaggle/input/bone-break-classification-image-...  Avulsion fracture  Train\n",
            "4  /kaggle/input/bone-break-classification-image-...  Avulsion fracture  Train\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "from matplotlib import cm\n",
        "from PIL import Image\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "import kagglehub\n",
        "\n",
        "# ----------------------------------------\n",
        "# 1. Download and Prepare the Dataset\n",
        "# ----------------------------------------\n",
        "path = kagglehub.dataset_download(\"pkdarabi/bone-break-classification-image-dataset\")\n",
        "path = os.path.join(path, 'Bone Break Classification/Bone Break Classification')\n",
        "\n",
        "def collect_image_data_paths(directory):\n",
        "    data = []\n",
        "    # Scan each class folder\n",
        "    for class_folder in os.listdir(directory):\n",
        "        class_path = os.path.join(directory, class_folder)\n",
        "        print(class_path)\n",
        "        if os.path.isdir(class_path):\n",
        "            for split in ['Train', 'Test']:\n",
        "                split_path = os.path.join(class_path, split)\n",
        "                if os.path.isdir(split_path):\n",
        "                    for image_name in os.listdir(split_path):\n",
        "                        image_path = os.path.join(split_path, image_name)\n",
        "                        data.append({'path': image_path, 'target': class_folder, 'split': split})\n",
        "    return data\n",
        "\n",
        "# Collect the data and create a DataFrame\n",
        "data = collect_image_data_paths(path)\n",
        "df = pd.DataFrame(data)\n",
        "print(df.head())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L5i-QfW0CVJc",
        "outputId": "d9f81e98-2238-4e2c-d454-1255b4331d07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 791 validated image filenames belonging to 10 classes.\n",
            "Found 198 validated image filenames belonging to 10 classes.\n",
            "Found 140 validated image filenames belonging to 10 classes.\n",
            "Train samples: 791\n",
            "Validation samples: 198\n",
            "Test samples: 140\n",
            "\n",
            "Train samples per class:\n",
            "target\n",
            "Fracture Dislocation     110\n",
            "Comminuted fracture      107\n",
            "Pathological fracture     93\n",
            "Avulsion fracture         87\n",
            "Greenstick fracture       85\n",
            "Hairline Fracture         81\n",
            "Impacted fracture         60\n",
            "Spiral Fracture           59\n",
            "Oblique fracture          55\n",
            "Longitudinal fracture     54\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Validation samples per class:\n",
            "target\n",
            "Fracture Dislocation     27\n",
            "Comminuted fracture      27\n",
            "Pathological fracture    23\n",
            "Avulsion fracture        22\n",
            "Greenstick fracture      21\n",
            "Hairline Fracture        20\n",
            "Spiral Fracture          15\n",
            "Impacted fracture        15\n",
            "Longitudinal fracture    14\n",
            "Oblique fracture         14\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Test samples per class:\n",
            "target\n",
            "Fracture Dislocation     19\n",
            "Pathological fracture    18\n",
            "Oblique fracture         16\n",
            "Greenstick fracture      16\n",
            "Comminuted fracture      14\n",
            "Avulsion fracture        14\n",
            "Spiral Fracture          12\n",
            "Longitudinal fracture    12\n",
            "Hairline Fracture        10\n",
            "Impacted fracture         9\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "batch_size = 10\n",
        "img_height = 256\n",
        "img_width = 256\n",
        "\n",
        "# Filter the full training DataFrame\n",
        "train_df_full = df[df['split'] == 'Train']\n",
        "\n",
        "# Perform a stratified split into training and validation sets (80% train, 20% validation)\n",
        "train_df, val_df = train_test_split(\n",
        "    train_df_full,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=train_df_full['target']\n",
        ")\n",
        "\n",
        "# Create separate ImageDataGenerators for training, validation, and testing\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Create the training generator\n",
        "train_generator = train_datagen.flow_from_dataframe(\n",
        "    dataframe=train_df,\n",
        "    x_col='path',\n",
        "    y_col='target',\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# Create the validation generator\n",
        "val_generator = val_datagen.flow_from_dataframe(\n",
        "    dataframe=val_df,\n",
        "    x_col='path',\n",
        "    y_col='target',\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# Create the test generator\n",
        "test_generator = test_datagen.flow_from_dataframe(\n",
        "    dataframe=df[df['split'] == 'Test'],\n",
        "    x_col='path',\n",
        "    y_col='target',\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# Print the total number of samples in each generator\n",
        "print(f'Train samples: {train_generator.samples}')\n",
        "print(f'Validation samples: {val_generator.samples}')\n",
        "print(f'Test samples: {test_generator.samples}')\n",
        "\n",
        "# Print the number of images per class for each set using value_counts()\n",
        "print(\"\\nTrain samples per class:\")\n",
        "print(train_df['target'].value_counts())\n",
        "\n",
        "print(\"\\nValidation samples per class:\")\n",
        "print(val_df['target'].value_counts())\n",
        "\n",
        "print(\"\\nTest samples per class:\")\n",
        "test_df = df[df['split'] == 'Test']\n",
        "print(test_df['target'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "kNPytxYQas9K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4d883fa-512d-4c68-bb42-995812e2a6cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 791 validated image filenames belonging to 10 classes.\n",
            "Found 791 validated image filenames belonging to 10 classes.\n",
            "Found 791 validated image filenames belonging to 10 classes.\n",
            "Found 791 validated image filenames belonging to 10 classes.\n",
            "Found 198 validated image filenames belonging to 10 classes.\n",
            "Found 198 validated image filenames belonging to 10 classes.\n",
            "Found 198 validated image filenames belonging to 10 classes.\n",
            "Found 198 validated image filenames belonging to 10 classes.\n",
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb3_notop.h5\n",
            "\u001b[1m43941136/43941136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 654ms/step - accuracy: 0.1410 - loss: 2.3521 - val_accuracy: 0.1566 - val_loss: 2.2318\n",
            "Epoch 2/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.1736 - loss: 2.2375 - val_accuracy: 0.2172 - val_loss: 2.1841\n",
            "Epoch 3/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.1986 - loss: 2.1954 - val_accuracy: 0.2323 - val_loss: 2.1458\n",
            "Epoch 4/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.2602 - loss: 2.0814 - val_accuracy: 0.2828 - val_loss: 2.1026\n",
            "Epoch 5/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.2928 - loss: 2.0758 - val_accuracy: 0.2727 - val_loss: 2.0710\n",
            "Epoch 6/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.3273 - loss: 1.9737 - val_accuracy: 0.3182 - val_loss: 2.0240\n",
            "Epoch 7/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.3557 - loss: 1.9410 - val_accuracy: 0.3131 - val_loss: 1.9975\n",
            "Epoch 8/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.3573 - loss: 1.8977 - val_accuracy: 0.3131 - val_loss: 1.9569\n",
            "Epoch 9/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.3886 - loss: 1.8165 - val_accuracy: 0.3283 - val_loss: 1.9345\n",
            "Epoch 10/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.4337 - loss: 1.7580 - val_accuracy: 0.3485 - val_loss: 1.9143\n",
            "Epoch 11/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.4330 - loss: 1.7120 - val_accuracy: 0.3384 - val_loss: 1.9039\n",
            "Epoch 12/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.4159 - loss: 1.7341 - val_accuracy: 0.3535 - val_loss: 1.8821\n",
            "Epoch 13/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.4798 - loss: 1.5975 - val_accuracy: 0.3535 - val_loss: 1.8673\n",
            "Epoch 14/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.5259 - loss: 1.5063 - val_accuracy: 0.3535 - val_loss: 1.8562\n",
            "Epoch 15/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.5172 - loss: 1.4645 - val_accuracy: 0.3636 - val_loss: 1.8425\n",
            "Epoch 16/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.5174 - loss: 1.4989 - val_accuracy: 0.3535 - val_loss: 1.8388\n",
            "Epoch 17/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.5401 - loss: 1.4004 - val_accuracy: 0.3737 - val_loss: 1.8269\n",
            "Epoch 18/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.5669 - loss: 1.3886 - val_accuracy: 0.3838 - val_loss: 1.8309\n",
            "Epoch 19/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.5499 - loss: 1.3544 - val_accuracy: 0.3838 - val_loss: 1.8310\n",
            "Epoch 20/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.5703 - loss: 1.3119 - val_accuracy: 0.3838 - val_loss: 1.8198\n",
            "Epoch 21/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.5866 - loss: 1.2612 - val_accuracy: 0.3586 - val_loss: 1.8356\n",
            "Epoch 22/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.5974 - loss: 1.2548 - val_accuracy: 0.3838 - val_loss: 1.8200\n",
            "Epoch 23/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.6111 - loss: 1.1575 - val_accuracy: 0.4192 - val_loss: 1.8094\n",
            "Epoch 24/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.6246 - loss: 1.1682 - val_accuracy: 0.4040 - val_loss: 1.8079\n",
            "Epoch 25/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.6520 - loss: 1.0654 - val_accuracy: 0.3990 - val_loss: 1.8152\n",
            "Epoch 26/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.6585 - loss: 1.0581 - val_accuracy: 0.3838 - val_loss: 1.8191\n",
            "Epoch 27/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.6499 - loss: 1.0483 - val_accuracy: 0.3889 - val_loss: 1.8047\n",
            "Epoch 28/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.7064 - loss: 0.9574 - val_accuracy: 0.3889 - val_loss: 1.8223\n",
            "Epoch 29/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.6458 - loss: 1.0569 - val_accuracy: 0.4293 - val_loss: 1.8340\n",
            "Epoch 30/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.7137 - loss: 0.9082 - val_accuracy: 0.3889 - val_loss: 1.8394\n",
            "Epoch 31/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.7027 - loss: 0.8705 - val_accuracy: 0.3889 - val_loss: 1.8304\n",
            "Epoch 32/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.7473 - loss: 0.8366 - val_accuracy: 0.4040 - val_loss: 1.8338\n",
            "Epoch 33/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.7322 - loss: 0.8503 - val_accuracy: 0.4343 - val_loss: 1.8207\n",
            "Epoch 34/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.7685 - loss: 0.7656 - val_accuracy: 0.3939 - val_loss: 1.8449\n",
            "Epoch 35/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.7540 - loss: 0.7932 - val_accuracy: 0.4141 - val_loss: 1.8433\n",
            "Epoch 36/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.7542 - loss: 0.7346 - val_accuracy: 0.4293 - val_loss: 1.8724\n",
            "Epoch 37/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.7747 - loss: 0.6898 - val_accuracy: 0.4040 - val_loss: 1.8796\n",
            "Epoch 38/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.7972 - loss: 0.6505 - val_accuracy: 0.4192 - val_loss: 1.8873\n",
            "Epoch 39/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.8052 - loss: 0.5951 - val_accuracy: 0.4394 - val_loss: 1.8865\n",
            "Epoch 40/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.8206 - loss: 0.6323 - val_accuracy: 0.4242 - val_loss: 1.8869\n",
            "Epoch 41/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.7876 - loss: 0.6188 - val_accuracy: 0.4040 - val_loss: 1.9240\n",
            "Epoch 42/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.8195 - loss: 0.5795 - val_accuracy: 0.4293 - val_loss: 1.9193\n",
            "Epoch 43/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.8064 - loss: 0.6205 - val_accuracy: 0.4394 - val_loss: 1.8955\n",
            "Epoch 44/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.8287 - loss: 0.5511 - val_accuracy: 0.4495 - val_loss: 1.9159\n",
            "Epoch 45/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.8611 - loss: 0.5025 - val_accuracy: 0.4495 - val_loss: 1.9265\n",
            "Epoch 46/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.8099 - loss: 0.5357 - val_accuracy: 0.4394 - val_loss: 1.9526\n",
            "Epoch 47/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.8802 - loss: 0.4687 - val_accuracy: 0.4343 - val_loss: 1.9535\n",
            "Epoch 48/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.8512 - loss: 0.4915 - val_accuracy: 0.4293 - val_loss: 1.9611\n",
            "Epoch 49/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.8474 - loss: 0.4600 - val_accuracy: 0.4242 - val_loss: 1.9764\n",
            "Epoch 50/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.8617 - loss: 0.4491 - val_accuracy: 0.4343 - val_loss: 2.0046\n",
            "Epoch 51/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.8928 - loss: 0.3835 - val_accuracy: 0.4242 - val_loss: 2.0178\n",
            "Epoch 52/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.8753 - loss: 0.3823 - val_accuracy: 0.4293 - val_loss: 2.0471\n",
            "Epoch 53/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.8842 - loss: 0.4036 - val_accuracy: 0.4192 - val_loss: 2.0267\n",
            "Epoch 54/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.8973 - loss: 0.3769 - val_accuracy: 0.4343 - val_loss: 2.0462\n",
            "Epoch 55/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.8857 - loss: 0.3729 - val_accuracy: 0.4343 - val_loss: 2.0813\n",
            "Epoch 56/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.8778 - loss: 0.3644 - val_accuracy: 0.4293 - val_loss: 2.0867\n",
            "Epoch 57/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.8914 - loss: 0.3237 - val_accuracy: 0.4141 - val_loss: 2.1004\n",
            "Epoch 58/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.9074 - loss: 0.3570 - val_accuracy: 0.4242 - val_loss: 2.1084\n",
            "Epoch 59/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.8906 - loss: 0.3377 - val_accuracy: 0.4444 - val_loss: 2.1104\n",
            "Epoch 60/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.8786 - loss: 0.3467 - val_accuracy: 0.4343 - val_loss: 2.1464\n",
            "Epoch 61/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9106 - loss: 0.3035 - val_accuracy: 0.4293 - val_loss: 2.1528\n",
            "Epoch 62/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9117 - loss: 0.3174 - val_accuracy: 0.3990 - val_loss: 2.2108\n",
            "Epoch 63/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9001 - loss: 0.3081 - val_accuracy: 0.4141 - val_loss: 2.1786\n",
            "Epoch 64/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.8996 - loss: 0.3353 - val_accuracy: 0.4141 - val_loss: 2.2235\n",
            "Epoch 65/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9247 - loss: 0.2763 - val_accuracy: 0.4343 - val_loss: 2.2149\n",
            "Epoch 66/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9173 - loss: 0.2663 - val_accuracy: 0.4394 - val_loss: 2.1934\n",
            "Epoch 67/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9276 - loss: 0.2401 - val_accuracy: 0.4394 - val_loss: 2.2351\n",
            "Epoch 68/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.9261 - loss: 0.2263 - val_accuracy: 0.4192 - val_loss: 2.2365\n",
            "Epoch 69/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9560 - loss: 0.2056 - val_accuracy: 0.4343 - val_loss: 2.2678\n",
            "Epoch 70/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.9229 - loss: 0.2551 - val_accuracy: 0.4343 - val_loss: 2.2914\n",
            "Epoch 71/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.9279 - loss: 0.2675 - val_accuracy: 0.4444 - val_loss: 2.2840\n",
            "Epoch 72/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9297 - loss: 0.2250 - val_accuracy: 0.4394 - val_loss: 2.2765\n",
            "Epoch 73/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9365 - loss: 0.2037 - val_accuracy: 0.4545 - val_loss: 2.3461\n",
            "Epoch 74/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.9223 - loss: 0.2199 - val_accuracy: 0.4343 - val_loss: 2.3049\n",
            "Epoch 75/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9224 - loss: 0.2438 - val_accuracy: 0.4545 - val_loss: 2.3582\n",
            "Epoch 76/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9567 - loss: 0.1791 - val_accuracy: 0.4343 - val_loss: 2.3602\n",
            "Epoch 77/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9538 - loss: 0.1663 - val_accuracy: 0.4343 - val_loss: 2.4226\n",
            "Epoch 78/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9275 - loss: 0.2147 - val_accuracy: 0.4444 - val_loss: 2.3774\n",
            "Epoch 79/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9290 - loss: 0.1977 - val_accuracy: 0.4192 - val_loss: 2.3749\n",
            "Epoch 80/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.9434 - loss: 0.2262 - val_accuracy: 0.4293 - val_loss: 2.3879\n",
            "Epoch 81/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9562 - loss: 0.1576 - val_accuracy: 0.4242 - val_loss: 2.4522\n",
            "Epoch 82/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.9516 - loss: 0.1954 - val_accuracy: 0.4394 - val_loss: 2.4239\n",
            "Epoch 83/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9540 - loss: 0.1580 - val_accuracy: 0.4545 - val_loss: 2.4449\n",
            "Epoch 84/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9369 - loss: 0.1817 - val_accuracy: 0.4343 - val_loss: 2.4541\n",
            "Epoch 85/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.9441 - loss: 0.1851 - val_accuracy: 0.4394 - val_loss: 2.4186\n",
            "Epoch 86/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9401 - loss: 0.1805 - val_accuracy: 0.4444 - val_loss: 2.4568\n",
            "Epoch 87/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.9301 - loss: 0.1832 - val_accuracy: 0.4343 - val_loss: 2.4494\n",
            "Epoch 88/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9704 - loss: 0.1214 - val_accuracy: 0.4495 - val_loss: 2.5374\n",
            "Epoch 89/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.9565 - loss: 0.1765 - val_accuracy: 0.4444 - val_loss: 2.4961\n",
            "Epoch 90/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9608 - loss: 0.1481 - val_accuracy: 0.4596 - val_loss: 2.4841\n",
            "Epoch 91/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9272 - loss: 0.2048 - val_accuracy: 0.4293 - val_loss: 2.5001\n",
            "Epoch 92/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9427 - loss: 0.2018 - val_accuracy: 0.4596 - val_loss: 2.4793\n",
            "Epoch 93/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9585 - loss: 0.1410 - val_accuracy: 0.4444 - val_loss: 2.5140\n",
            "Epoch 94/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9477 - loss: 0.1461 - val_accuracy: 0.4646 - val_loss: 2.5355\n",
            "Epoch 95/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9596 - loss: 0.1271 - val_accuracy: 0.4343 - val_loss: 2.5344\n",
            "Epoch 96/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9648 - loss: 0.1246 - val_accuracy: 0.4545 - val_loss: 2.5843\n",
            "Epoch 97/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9433 - loss: 0.1662 - val_accuracy: 0.4293 - val_loss: 2.5825\n",
            "Epoch 98/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9604 - loss: 0.1370 - val_accuracy: 0.4343 - val_loss: 2.5874\n",
            "Epoch 99/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.9434 - loss: 0.1414 - val_accuracy: 0.4545 - val_loss: 2.5893\n",
            "Epoch 100/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9524 - loss: 0.1493 - val_accuracy: 0.4343 - val_loss: 2.6656\n",
            "Epoch 1/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 363ms/step - accuracy: 0.1055 - loss: 2.3898 - val_accuracy: 0.2121 - val_loss: 2.2178\n",
            "Epoch 2/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.1307 - loss: 2.2607 - val_accuracy: 0.2778 - val_loss: 2.1721\n",
            "Epoch 3/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.2225 - loss: 2.1863 - val_accuracy: 0.2879 - val_loss: 2.1285\n",
            "Epoch 4/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.2180 - loss: 2.1350 - val_accuracy: 0.3182 - val_loss: 2.0917\n",
            "Epoch 5/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.2750 - loss: 2.0513 - val_accuracy: 0.3283 - val_loss: 2.0478\n",
            "Epoch 6/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.3180 - loss: 2.0012 - val_accuracy: 0.3232 - val_loss: 2.0093\n",
            "Epoch 7/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.3299 - loss: 1.9496 - val_accuracy: 0.3333 - val_loss: 1.9785\n",
            "Epoch 8/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.3951 - loss: 1.8568 - val_accuracy: 0.3434 - val_loss: 1.9387\n",
            "Epoch 9/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.3576 - loss: 1.8989 - val_accuracy: 0.3283 - val_loss: 1.9093\n",
            "Epoch 10/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.3987 - loss: 1.8036 - val_accuracy: 0.3535 - val_loss: 1.8809\n",
            "Epoch 11/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.4137 - loss: 1.7199 - val_accuracy: 0.3333 - val_loss: 1.8647\n",
            "Epoch 12/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.4202 - loss: 1.7115 - val_accuracy: 0.3535 - val_loss: 1.8516\n",
            "Epoch 13/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.4383 - loss: 1.6534 - val_accuracy: 0.3737 - val_loss: 1.8224\n",
            "Epoch 14/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.4478 - loss: 1.6228 - val_accuracy: 0.3737 - val_loss: 1.8064\n",
            "Epoch 15/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.5138 - loss: 1.5059 - val_accuracy: 0.3737 - val_loss: 1.7968\n",
            "Epoch 16/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.4881 - loss: 1.5270 - val_accuracy: 0.3737 - val_loss: 1.7905\n",
            "Epoch 17/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.5356 - loss: 1.4169 - val_accuracy: 0.3939 - val_loss: 1.7767\n",
            "Epoch 18/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.5550 - loss: 1.3581 - val_accuracy: 0.3687 - val_loss: 1.7771\n",
            "Epoch 19/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.5454 - loss: 1.3393 - val_accuracy: 0.3586 - val_loss: 1.7678\n",
            "Epoch 20/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.5789 - loss: 1.3196 - val_accuracy: 0.3889 - val_loss: 1.7528\n",
            "Epoch 21/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.5616 - loss: 1.3309 - val_accuracy: 0.3687 - val_loss: 1.7557\n",
            "Epoch 22/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.6033 - loss: 1.1968 - val_accuracy: 0.4091 - val_loss: 1.7352\n",
            "Epoch 23/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.5700 - loss: 1.2324 - val_accuracy: 0.4091 - val_loss: 1.7470\n",
            "Epoch 24/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.6159 - loss: 1.2126 - val_accuracy: 0.3990 - val_loss: 1.7530\n",
            "Epoch 25/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.6075 - loss: 1.1222 - val_accuracy: 0.4242 - val_loss: 1.7477\n",
            "Epoch 26/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.6380 - loss: 1.1037 - val_accuracy: 0.4192 - val_loss: 1.7410\n",
            "Epoch 27/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.6592 - loss: 1.0266 - val_accuracy: 0.4394 - val_loss: 1.7237\n",
            "Epoch 28/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.6867 - loss: 1.0126 - val_accuracy: 0.4394 - val_loss: 1.7359\n",
            "Epoch 29/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.6929 - loss: 0.9703 - val_accuracy: 0.4293 - val_loss: 1.7468\n",
            "Epoch 30/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.7112 - loss: 0.9511 - val_accuracy: 0.4293 - val_loss: 1.7490\n",
            "Epoch 31/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.7179 - loss: 0.8888 - val_accuracy: 0.4394 - val_loss: 1.7591\n",
            "Epoch 32/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.7012 - loss: 0.9248 - val_accuracy: 0.4343 - val_loss: 1.7548\n",
            "Epoch 33/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.6953 - loss: 0.9106 - val_accuracy: 0.4495 - val_loss: 1.7579\n",
            "Epoch 34/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.7489 - loss: 0.7864 - val_accuracy: 0.4444 - val_loss: 1.7712\n",
            "Epoch 35/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.7522 - loss: 0.7989 - val_accuracy: 0.4343 - val_loss: 1.7489\n",
            "Epoch 36/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.7435 - loss: 0.7942 - val_accuracy: 0.4495 - val_loss: 1.7512\n",
            "Epoch 37/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.7758 - loss: 0.6948 - val_accuracy: 0.4394 - val_loss: 1.7585\n",
            "Epoch 38/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.7677 - loss: 0.7224 - val_accuracy: 0.4394 - val_loss: 1.7603\n",
            "Epoch 39/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.7858 - loss: 0.7215 - val_accuracy: 0.4394 - val_loss: 1.7708\n",
            "Epoch 40/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.7610 - loss: 0.7291 - val_accuracy: 0.4444 - val_loss: 1.7837\n",
            "Epoch 41/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.7615 - loss: 0.7030 - val_accuracy: 0.4646 - val_loss: 1.8064\n",
            "Epoch 42/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.7981 - loss: 0.6274 - val_accuracy: 0.4394 - val_loss: 1.7945\n",
            "Epoch 43/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.8100 - loss: 0.6131 - val_accuracy: 0.4293 - val_loss: 1.8117\n",
            "Epoch 44/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.8145 - loss: 0.6061 - val_accuracy: 0.4343 - val_loss: 1.8068\n",
            "Epoch 45/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.8345 - loss: 0.5524 - val_accuracy: 0.4545 - val_loss: 1.8402\n",
            "Epoch 46/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.8374 - loss: 0.5227 - val_accuracy: 0.4646 - val_loss: 1.8311\n",
            "Epoch 47/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.8244 - loss: 0.5580 - val_accuracy: 0.4495 - val_loss: 1.8236\n",
            "Epoch 48/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.8451 - loss: 0.4794 - val_accuracy: 0.4444 - val_loss: 1.8513\n",
            "Epoch 49/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.8708 - loss: 0.4630 - val_accuracy: 0.4444 - val_loss: 1.8556\n",
            "Epoch 50/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.8798 - loss: 0.4604 - val_accuracy: 0.4293 - val_loss: 1.8733\n",
            "Epoch 51/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.8673 - loss: 0.4605 - val_accuracy: 0.4343 - val_loss: 1.8696\n",
            "Epoch 52/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.8650 - loss: 0.4755 - val_accuracy: 0.4545 - val_loss: 1.8795\n",
            "Epoch 53/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.8707 - loss: 0.4202 - val_accuracy: 0.4444 - val_loss: 1.8827\n",
            "Epoch 54/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.8809 - loss: 0.4041 - val_accuracy: 0.4293 - val_loss: 1.9194\n",
            "Epoch 55/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.8944 - loss: 0.3614 - val_accuracy: 0.4242 - val_loss: 1.9371\n",
            "Epoch 56/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.8645 - loss: 0.3919 - val_accuracy: 0.4343 - val_loss: 1.9288\n",
            "Epoch 57/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.8943 - loss: 0.4084 - val_accuracy: 0.4394 - val_loss: 1.9651\n",
            "Epoch 58/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9023 - loss: 0.3406 - val_accuracy: 0.4495 - val_loss: 1.9678\n",
            "Epoch 59/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.8686 - loss: 0.4125 - val_accuracy: 0.4646 - val_loss: 1.9553\n",
            "Epoch 60/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.9098 - loss: 0.3521 - val_accuracy: 0.4495 - val_loss: 1.9971\n",
            "Epoch 61/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.8855 - loss: 0.3456 - val_accuracy: 0.4444 - val_loss: 1.9891\n",
            "Epoch 62/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.9111 - loss: 0.2968 - val_accuracy: 0.4596 - val_loss: 1.9868\n",
            "Epoch 63/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.9313 - loss: 0.2790 - val_accuracy: 0.4596 - val_loss: 2.0109\n",
            "Epoch 64/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.9147 - loss: 0.2621 - val_accuracy: 0.4444 - val_loss: 2.0406\n",
            "Epoch 65/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.9124 - loss: 0.2715 - val_accuracy: 0.4343 - val_loss: 2.0350\n",
            "Epoch 66/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.9337 - loss: 0.2355 - val_accuracy: 0.4394 - val_loss: 2.0599\n",
            "Epoch 67/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.9234 - loss: 0.2495 - val_accuracy: 0.4444 - val_loss: 2.0751\n",
            "Epoch 68/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.9265 - loss: 0.2557 - val_accuracy: 0.4242 - val_loss: 2.0870\n",
            "Epoch 69/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.9147 - loss: 0.2767 - val_accuracy: 0.4141 - val_loss: 2.0858\n",
            "Epoch 70/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.9154 - loss: 0.3071 - val_accuracy: 0.4495 - val_loss: 2.1084\n",
            "Epoch 71/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.9148 - loss: 0.2365 - val_accuracy: 0.4646 - val_loss: 2.1205\n",
            "Epoch 72/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.9216 - loss: 0.2366 - val_accuracy: 0.4495 - val_loss: 2.1387\n",
            "Epoch 73/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.9204 - loss: 0.2296 - val_accuracy: 0.4596 - val_loss: 2.1450\n",
            "Epoch 74/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.9167 - loss: 0.2498 - val_accuracy: 0.4545 - val_loss: 2.1308\n",
            "Epoch 75/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.9105 - loss: 0.2744 - val_accuracy: 0.4495 - val_loss: 2.1453\n",
            "Epoch 76/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.9442 - loss: 0.2054 - val_accuracy: 0.4646 - val_loss: 2.1098\n",
            "Epoch 77/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.9452 - loss: 0.1989 - val_accuracy: 0.4646 - val_loss: 2.1562\n",
            "Epoch 78/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.9520 - loss: 0.1822 - val_accuracy: 0.4697 - val_loss: 2.1923\n",
            "Epoch 79/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.9235 - loss: 0.2330 - val_accuracy: 0.4596 - val_loss: 2.2022\n",
            "Epoch 80/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.9498 - loss: 0.1859 - val_accuracy: 0.4495 - val_loss: 2.1918\n",
            "Epoch 81/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.9396 - loss: 0.1820 - val_accuracy: 0.4646 - val_loss: 2.2008\n",
            "Epoch 82/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.9494 - loss: 0.1874 - val_accuracy: 0.4545 - val_loss: 2.2072\n",
            "Epoch 83/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.9432 - loss: 0.2008 - val_accuracy: 0.4495 - val_loss: 2.2754\n",
            "Epoch 84/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.9520 - loss: 0.1671 - val_accuracy: 0.4596 - val_loss: 2.2584\n",
            "Epoch 85/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.9221 - loss: 0.2005 - val_accuracy: 0.4444 - val_loss: 2.2719\n",
            "Epoch 86/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.9418 - loss: 0.1717 - val_accuracy: 0.4646 - val_loss: 2.2848\n",
            "Epoch 87/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.9626 - loss: 0.1316 - val_accuracy: 0.4495 - val_loss: 2.3241\n",
            "Epoch 88/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.9423 - loss: 0.1987 - val_accuracy: 0.4293 - val_loss: 2.2663\n",
            "Epoch 89/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.9434 - loss: 0.1640 - val_accuracy: 0.4192 - val_loss: 2.3132\n",
            "Epoch 90/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.9526 - loss: 0.1661 - val_accuracy: 0.4293 - val_loss: 2.3373\n",
            "Epoch 91/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.9674 - loss: 0.1610 - val_accuracy: 0.4495 - val_loss: 2.3207\n",
            "Epoch 92/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.9828 - loss: 0.1157 - val_accuracy: 0.4293 - val_loss: 2.3578\n",
            "Epoch 93/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.9532 - loss: 0.1579 - val_accuracy: 0.4394 - val_loss: 2.3590\n",
            "Epoch 94/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.9588 - loss: 0.1344 - val_accuracy: 0.4444 - val_loss: 2.3714\n",
            "Epoch 95/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.9443 - loss: 0.1773 - val_accuracy: 0.4545 - val_loss: 2.3385\n",
            "Epoch 96/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.9493 - loss: 0.1889 - val_accuracy: 0.4596 - val_loss: 2.3284\n",
            "Epoch 97/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.9670 - loss: 0.1245 - val_accuracy: 0.4596 - val_loss: 2.3693\n",
            "Epoch 98/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.9705 - loss: 0.1005 - val_accuracy: 0.4646 - val_loss: 2.4003\n",
            "Epoch 99/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.9631 - loss: 0.1273 - val_accuracy: 0.4545 - val_loss: 2.4077\n",
            "Epoch 100/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9699 - loss: 0.1190 - val_accuracy: 0.4596 - val_loss: 2.4145\n",
            "Epoch 1/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 371ms/step - accuracy: 0.1402 - loss: 2.2997 - val_accuracy: 0.1566 - val_loss: 2.2440\n",
            "Epoch 2/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.1443 - loss: 2.2550 - val_accuracy: 0.2374 - val_loss: 2.2181\n",
            "Epoch 3/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.1758 - loss: 2.2396 - val_accuracy: 0.2323 - val_loss: 2.1931\n",
            "Epoch 4/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.2141 - loss: 2.1821 - val_accuracy: 0.2475 - val_loss: 2.1704\n",
            "Epoch 5/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.1884 - loss: 2.1906 - val_accuracy: 0.2828 - val_loss: 2.1482\n",
            "Epoch 6/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.2375 - loss: 2.1299 - val_accuracy: 0.2980 - val_loss: 2.1281\n",
            "Epoch 7/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.2531 - loss: 2.1079 - val_accuracy: 0.2980 - val_loss: 2.1037\n",
            "Epoch 8/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.2515 - loss: 2.0774 - val_accuracy: 0.2980 - val_loss: 2.0876\n",
            "Epoch 9/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - accuracy: 0.3009 - loss: 2.0337 - val_accuracy: 0.2879 - val_loss: 2.0688\n",
            "Epoch 10/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.3266 - loss: 1.9871 - val_accuracy: 0.2980 - val_loss: 2.0550\n",
            "Epoch 11/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.3350 - loss: 1.9529 - val_accuracy: 0.2980 - val_loss: 2.0461\n",
            "Epoch 12/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.3050 - loss: 2.0105 - val_accuracy: 0.2879 - val_loss: 2.0425\n",
            "Epoch 13/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.2993 - loss: 1.9472 - val_accuracy: 0.3030 - val_loss: 2.0291\n",
            "Epoch 14/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.3291 - loss: 1.9135 - val_accuracy: 0.3384 - val_loss: 2.0138\n",
            "Epoch 15/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 40ms/step - accuracy: 0.3631 - loss: 1.8272 - val_accuracy: 0.3283 - val_loss: 2.0081\n",
            "Epoch 16/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.3439 - loss: 1.8431 - val_accuracy: 0.3333 - val_loss: 2.0088\n",
            "Epoch 17/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.3783 - loss: 1.8231 - val_accuracy: 0.3333 - val_loss: 2.0089\n",
            "Epoch 18/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.4336 - loss: 1.7323 - val_accuracy: 0.3333 - val_loss: 2.0041\n",
            "Epoch 19/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.4021 - loss: 1.7427 - val_accuracy: 0.3131 - val_loss: 1.9997\n",
            "Epoch 20/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 40ms/step - accuracy: 0.4189 - loss: 1.7065 - val_accuracy: 0.3485 - val_loss: 1.9911\n",
            "Epoch 21/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.4162 - loss: 1.6838 - val_accuracy: 0.3232 - val_loss: 2.0087\n",
            "Epoch 22/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.4298 - loss: 1.6897 - val_accuracy: 0.3182 - val_loss: 1.9943\n",
            "Epoch 23/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.4154 - loss: 1.6419 - val_accuracy: 0.3384 - val_loss: 1.9988\n",
            "Epoch 24/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.4941 - loss: 1.5966 - val_accuracy: 0.3030 - val_loss: 2.0037\n",
            "Epoch 25/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.4898 - loss: 1.5641 - val_accuracy: 0.3182 - val_loss: 2.0019\n",
            "Epoch 26/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.4727 - loss: 1.5789 - val_accuracy: 0.3182 - val_loss: 2.0093\n",
            "Epoch 27/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.4644 - loss: 1.5823 - val_accuracy: 0.3384 - val_loss: 2.0041\n",
            "Epoch 28/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - accuracy: 0.5120 - loss: 1.4759 - val_accuracy: 0.3232 - val_loss: 1.9988\n",
            "Epoch 29/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.5206 - loss: 1.4507 - val_accuracy: 0.3283 - val_loss: 2.0067\n",
            "Epoch 30/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.5220 - loss: 1.4498 - val_accuracy: 0.3434 - val_loss: 2.0075\n",
            "Epoch 31/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.5115 - loss: 1.4656 - val_accuracy: 0.3434 - val_loss: 2.0095\n",
            "Epoch 32/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.5256 - loss: 1.4520 - val_accuracy: 0.3333 - val_loss: 2.0101\n",
            "Epoch 33/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.5323 - loss: 1.3927 - val_accuracy: 0.3333 - val_loss: 2.0051\n",
            "Epoch 34/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.5395 - loss: 1.3583 - val_accuracy: 0.3384 - val_loss: 2.0183\n",
            "Epoch 35/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.5563 - loss: 1.3440 - val_accuracy: 0.3283 - val_loss: 2.0146\n",
            "Epoch 36/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.5802 - loss: 1.3385 - val_accuracy: 0.3333 - val_loss: 2.0297\n",
            "Epoch 37/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.5809 - loss: 1.2343 - val_accuracy: 0.3283 - val_loss: 2.0462\n",
            "Epoch 38/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.5797 - loss: 1.2881 - val_accuracy: 0.3333 - val_loss: 2.0634\n",
            "Epoch 39/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 40ms/step - accuracy: 0.6088 - loss: 1.2210 - val_accuracy: 0.3485 - val_loss: 2.0488\n",
            "Epoch 40/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.5677 - loss: 1.2887 - val_accuracy: 0.3485 - val_loss: 2.0638\n",
            "Epoch 41/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.5798 - loss: 1.2278 - val_accuracy: 0.3434 - val_loss: 2.0563\n",
            "Epoch 42/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - accuracy: 0.6282 - loss: 1.1618 - val_accuracy: 0.3535 - val_loss: 2.0543\n",
            "Epoch 43/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.6227 - loss: 1.1589 - val_accuracy: 0.3485 - val_loss: 2.0614\n",
            "Epoch 44/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.6661 - loss: 1.0663 - val_accuracy: 0.3081 - val_loss: 2.1146\n",
            "Epoch 45/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.6450 - loss: 1.0614 - val_accuracy: 0.3232 - val_loss: 2.1100\n",
            "Epoch 46/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.6568 - loss: 1.0793 - val_accuracy: 0.3283 - val_loss: 2.1134\n",
            "Epoch 47/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.6571 - loss: 1.0618 - val_accuracy: 0.3283 - val_loss: 2.1157\n",
            "Epoch 48/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.6582 - loss: 1.0046 - val_accuracy: 0.3333 - val_loss: 2.1129\n",
            "Epoch 49/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - accuracy: 0.6799 - loss: 1.0098 - val_accuracy: 0.3434 - val_loss: 2.1185\n",
            "Epoch 50/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - accuracy: 0.6694 - loss: 1.0425 - val_accuracy: 0.3535 - val_loss: 2.1112\n",
            "Epoch 51/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - accuracy: 0.6654 - loss: 1.0246 - val_accuracy: 0.3687 - val_loss: 2.1365\n",
            "Epoch 52/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.7048 - loss: 0.9105 - val_accuracy: 0.3333 - val_loss: 2.1539\n",
            "Epoch 53/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 40ms/step - accuracy: 0.7063 - loss: 0.9549 - val_accuracy: 0.3485 - val_loss: 2.1466\n",
            "Epoch 54/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.7162 - loss: 0.8971 - val_accuracy: 0.3384 - val_loss: 2.1741\n",
            "Epoch 55/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.7447 - loss: 0.8865 - val_accuracy: 0.3535 - val_loss: 2.1948\n",
            "Epoch 56/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.6902 - loss: 0.9189 - val_accuracy: 0.3636 - val_loss: 2.1628\n",
            "Epoch 57/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.7100 - loss: 0.9202 - val_accuracy: 0.3636 - val_loss: 2.2163\n",
            "Epoch 58/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.6805 - loss: 0.9581 - val_accuracy: 0.3535 - val_loss: 2.1871\n",
            "Epoch 59/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.7535 - loss: 0.8050 - val_accuracy: 0.3434 - val_loss: 2.2330\n",
            "Epoch 60/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.7278 - loss: 0.8294 - val_accuracy: 0.3737 - val_loss: 2.2336\n",
            "Epoch 61/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.7423 - loss: 0.7794 - val_accuracy: 0.3687 - val_loss: 2.2527\n",
            "Epoch 62/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - accuracy: 0.7401 - loss: 0.7888 - val_accuracy: 0.3384 - val_loss: 2.2500\n",
            "Epoch 63/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - accuracy: 0.7314 - loss: 0.7962 - val_accuracy: 0.3434 - val_loss: 2.2749\n",
            "Epoch 64/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - accuracy: 0.7513 - loss: 0.7927 - val_accuracy: 0.3434 - val_loss: 2.2949\n",
            "Epoch 65/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.7517 - loss: 0.8138 - val_accuracy: 0.3384 - val_loss: 2.2967\n",
            "Epoch 66/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - accuracy: 0.7790 - loss: 0.6860 - val_accuracy: 0.3384 - val_loss: 2.3086\n",
            "Epoch 67/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.7927 - loss: 0.6904 - val_accuracy: 0.3636 - val_loss: 2.2853\n",
            "Epoch 68/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.8110 - loss: 0.6771 - val_accuracy: 0.3687 - val_loss: 2.3300\n",
            "Epoch 69/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 40ms/step - accuracy: 0.7759 - loss: 0.6877 - val_accuracy: 0.3636 - val_loss: 2.3308\n",
            "Epoch 70/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.7903 - loss: 0.7087 - val_accuracy: 0.3636 - val_loss: 2.3557\n",
            "Epoch 71/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.8149 - loss: 0.6575 - val_accuracy: 0.3586 - val_loss: 2.3864\n",
            "Epoch 72/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.7789 - loss: 0.6772 - val_accuracy: 0.3838 - val_loss: 2.3719\n",
            "Epoch 73/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.7762 - loss: 0.6654 - val_accuracy: 0.3535 - val_loss: 2.3943\n",
            "Epoch 74/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 40ms/step - accuracy: 0.8211 - loss: 0.6218 - val_accuracy: 0.3535 - val_loss: 2.4365\n",
            "Epoch 75/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.7873 - loss: 0.6261 - val_accuracy: 0.3535 - val_loss: 2.4154\n",
            "Epoch 76/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.8268 - loss: 0.6056 - val_accuracy: 0.3535 - val_loss: 2.4149\n",
            "Epoch 77/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.8128 - loss: 0.5733 - val_accuracy: 0.3636 - val_loss: 2.4394\n",
            "Epoch 78/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.8288 - loss: 0.5629 - val_accuracy: 0.3636 - val_loss: 2.4517\n",
            "Epoch 79/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.8318 - loss: 0.5446 - val_accuracy: 0.3838 - val_loss: 2.4623\n",
            "Epoch 80/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.8446 - loss: 0.5349 - val_accuracy: 0.3636 - val_loss: 2.4910\n",
            "Epoch 81/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - accuracy: 0.8214 - loss: 0.5568 - val_accuracy: 0.3687 - val_loss: 2.4756\n",
            "Epoch 82/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.8600 - loss: 0.4614 - val_accuracy: 0.3283 - val_loss: 2.5109\n",
            "Epoch 83/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.8622 - loss: 0.4531 - val_accuracy: 0.3737 - val_loss: 2.5036\n",
            "Epoch 84/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - accuracy: 0.8070 - loss: 0.6476 - val_accuracy: 0.3737 - val_loss: 2.5206\n",
            "Epoch 85/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.8364 - loss: 0.5249 - val_accuracy: 0.3687 - val_loss: 2.5285\n",
            "Epoch 86/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - accuracy: 0.8308 - loss: 0.5294 - val_accuracy: 0.3737 - val_loss: 2.5436\n",
            "Epoch 87/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.8216 - loss: 0.5386 - val_accuracy: 0.3687 - val_loss: 2.5527\n",
            "Epoch 88/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.8699 - loss: 0.4475 - val_accuracy: 0.3737 - val_loss: 2.5668\n",
            "Epoch 89/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 40ms/step - accuracy: 0.8563 - loss: 0.4655 - val_accuracy: 0.3586 - val_loss: 2.5882\n",
            "Epoch 90/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 40ms/step - accuracy: 0.8534 - loss: 0.4742 - val_accuracy: 0.3586 - val_loss: 2.5952\n",
            "Epoch 91/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.8689 - loss: 0.4300 - val_accuracy: 0.3434 - val_loss: 2.5871\n",
            "Epoch 92/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.8731 - loss: 0.4088 - val_accuracy: 0.3687 - val_loss: 2.6000\n",
            "Epoch 93/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.8297 - loss: 0.4761 - val_accuracy: 0.3485 - val_loss: 2.6442\n",
            "Epoch 94/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.8759 - loss: 0.3914 - val_accuracy: 0.3687 - val_loss: 2.6858\n",
            "Epoch 95/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.8705 - loss: 0.4299 - val_accuracy: 0.3687 - val_loss: 2.7023\n",
            "Epoch 96/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.8444 - loss: 0.4798 - val_accuracy: 0.3788 - val_loss: 2.6537\n",
            "Epoch 97/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - accuracy: 0.8563 - loss: 0.4485 - val_accuracy: 0.3788 - val_loss: 2.6940\n",
            "Epoch 98/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - accuracy: 0.8635 - loss: 0.4252 - val_accuracy: 0.3838 - val_loss: 2.6459\n",
            "Epoch 99/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - accuracy: 0.8836 - loss: 0.4175 - val_accuracy: 0.3838 - val_loss: 2.6735\n",
            "Epoch 100/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.8965 - loss: 0.3579 - val_accuracy: 0.3737 - val_loss: 2.7595\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-d69c1f3b1c1c>:53: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n",
            "  colored = cm.get_cmap('jet')(norm)[..., :3]   # floats [0,1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 385ms/step - accuracy: 0.1184 - loss: 2.3096 - val_accuracy: 0.2020 - val_loss: 2.2252\n",
            "Epoch 2/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.1653 - loss: 2.2424 - val_accuracy: 0.2424 - val_loss: 2.1783\n",
            "Epoch 3/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 57ms/step - accuracy: 0.2058 - loss: 2.1776 - val_accuracy: 0.2626 - val_loss: 2.1358\n",
            "Epoch 4/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 57ms/step - accuracy: 0.2591 - loss: 2.1080 - val_accuracy: 0.3131 - val_loss: 2.0966\n",
            "Epoch 5/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 56ms/step - accuracy: 0.2964 - loss: 2.0057 - val_accuracy: 0.3182 - val_loss: 2.0577\n",
            "Epoch 6/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 56ms/step - accuracy: 0.2929 - loss: 2.0241 - val_accuracy: 0.3333 - val_loss: 2.0249\n",
            "Epoch 7/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 57ms/step - accuracy: 0.3285 - loss: 1.9418 - val_accuracy: 0.3434 - val_loss: 1.9820\n",
            "Epoch 8/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 56ms/step - accuracy: 0.3567 - loss: 1.9008 - val_accuracy: 0.3636 - val_loss: 1.9431\n",
            "Epoch 9/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 56ms/step - accuracy: 0.3713 - loss: 1.8812 - val_accuracy: 0.3737 - val_loss: 1.9221\n",
            "Epoch 10/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 57ms/step - accuracy: 0.4419 - loss: 1.7720 - val_accuracy: 0.3636 - val_loss: 1.8884\n",
            "Epoch 11/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - accuracy: 0.4283 - loss: 1.6920 - val_accuracy: 0.3737 - val_loss: 1.8741\n",
            "Epoch 12/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - accuracy: 0.4718 - loss: 1.6573 - val_accuracy: 0.3838 - val_loss: 1.8529\n",
            "Epoch 13/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 57ms/step - accuracy: 0.4504 - loss: 1.6517 - val_accuracy: 0.3939 - val_loss: 1.8302\n",
            "Epoch 14/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 58ms/step - accuracy: 0.4640 - loss: 1.6146 - val_accuracy: 0.3737 - val_loss: 1.8120\n",
            "Epoch 15/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 57ms/step - accuracy: 0.5090 - loss: 1.5117 - val_accuracy: 0.3737 - val_loss: 1.7924\n",
            "Epoch 16/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 58ms/step - accuracy: 0.5202 - loss: 1.4914 - val_accuracy: 0.3838 - val_loss: 1.7867\n",
            "Epoch 17/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 57ms/step - accuracy: 0.5032 - loss: 1.5080 - val_accuracy: 0.4040 - val_loss: 1.7742\n",
            "Epoch 18/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 56ms/step - accuracy: 0.5285 - loss: 1.4360 - val_accuracy: 0.3838 - val_loss: 1.7765\n",
            "Epoch 19/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 57ms/step - accuracy: 0.5500 - loss: 1.4169 - val_accuracy: 0.3990 - val_loss: 1.7683\n",
            "Epoch 20/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.6028 - loss: 1.3110 - val_accuracy: 0.3990 - val_loss: 1.7491\n",
            "Epoch 21/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 56ms/step - accuracy: 0.5716 - loss: 1.3196 - val_accuracy: 0.3889 - val_loss: 1.7492\n",
            "Epoch 22/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.6187 - loss: 1.2784 - val_accuracy: 0.3990 - val_loss: 1.7504\n",
            "Epoch 23/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 57ms/step - accuracy: 0.6016 - loss: 1.2207 - val_accuracy: 0.3889 - val_loss: 1.7521\n",
            "Epoch 24/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 58ms/step - accuracy: 0.6267 - loss: 1.2175 - val_accuracy: 0.4242 - val_loss: 1.7307\n",
            "Epoch 25/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.6702 - loss: 1.0669 - val_accuracy: 0.4091 - val_loss: 1.7298\n",
            "Epoch 26/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 58ms/step - accuracy: 0.6587 - loss: 1.0689 - val_accuracy: 0.4293 - val_loss: 1.7319\n",
            "Epoch 27/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 63ms/step - accuracy: 0.6391 - loss: 1.0726 - val_accuracy: 0.4293 - val_loss: 1.7334\n",
            "Epoch 28/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 62ms/step - accuracy: 0.7022 - loss: 0.9658 - val_accuracy: 0.4040 - val_loss: 1.7454\n",
            "Epoch 29/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 67ms/step - accuracy: 0.6806 - loss: 0.9888 - val_accuracy: 0.4141 - val_loss: 1.7406\n",
            "Epoch 30/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 63ms/step - accuracy: 0.7366 - loss: 0.9153 - val_accuracy: 0.4343 - val_loss: 1.7578\n",
            "Epoch 31/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 56ms/step - accuracy: 0.7329 - loss: 0.9174 - val_accuracy: 0.4444 - val_loss: 1.7414\n",
            "Epoch 32/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.7100 - loss: 0.9336 - val_accuracy: 0.4444 - val_loss: 1.7327\n",
            "Epoch 33/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 63ms/step - accuracy: 0.7329 - loss: 0.8365 - val_accuracy: 0.4495 - val_loss: 1.7591\n",
            "Epoch 34/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 63ms/step - accuracy: 0.7446 - loss: 0.8101 - val_accuracy: 0.4596 - val_loss: 1.7468\n",
            "Epoch 35/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - accuracy: 0.7876 - loss: 0.7279 - val_accuracy: 0.4545 - val_loss: 1.7472\n",
            "Epoch 36/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - accuracy: 0.7773 - loss: 0.7687 - val_accuracy: 0.4242 - val_loss: 1.7673\n",
            "Epoch 37/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 71ms/step - accuracy: 0.7560 - loss: 0.7655 - val_accuracy: 0.4293 - val_loss: 1.7632\n",
            "Epoch 38/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 57ms/step - accuracy: 0.7538 - loss: 0.7347 - val_accuracy: 0.4444 - val_loss: 1.7646\n",
            "Epoch 39/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 58ms/step - accuracy: 0.7937 - loss: 0.7093 - val_accuracy: 0.4444 - val_loss: 1.7741\n",
            "Epoch 40/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 58ms/step - accuracy: 0.7903 - loss: 0.6820 - val_accuracy: 0.4444 - val_loss: 1.7943\n",
            "Epoch 41/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - accuracy: 0.7848 - loss: 0.7125 - val_accuracy: 0.4848 - val_loss: 1.7945\n",
            "Epoch 42/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 58ms/step - accuracy: 0.7984 - loss: 0.6192 - val_accuracy: 0.4747 - val_loss: 1.7854\n",
            "Epoch 43/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 57ms/step - accuracy: 0.8512 - loss: 0.5478 - val_accuracy: 0.4596 - val_loss: 1.8029\n",
            "Epoch 44/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 57ms/step - accuracy: 0.8092 - loss: 0.6133 - val_accuracy: 0.4697 - val_loss: 1.7949\n",
            "Epoch 45/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 56ms/step - accuracy: 0.8504 - loss: 0.5295 - val_accuracy: 0.4444 - val_loss: 1.8106\n",
            "Epoch 46/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 56ms/step - accuracy: 0.8276 - loss: 0.5981 - val_accuracy: 0.4596 - val_loss: 1.8300\n",
            "Epoch 47/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 58ms/step - accuracy: 0.8270 - loss: 0.5345 - val_accuracy: 0.4848 - val_loss: 1.8411\n",
            "Epoch 48/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.8554 - loss: 0.4674 - val_accuracy: 0.4848 - val_loss: 1.8475\n",
            "Epoch 49/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - accuracy: 0.8460 - loss: 0.4906 - val_accuracy: 0.4747 - val_loss: 1.8533\n",
            "Epoch 50/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 57ms/step - accuracy: 0.8469 - loss: 0.4940 - val_accuracy: 0.4596 - val_loss: 1.8562\n",
            "Epoch 51/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 57ms/step - accuracy: 0.8302 - loss: 0.5366 - val_accuracy: 0.4192 - val_loss: 1.8965\n",
            "Epoch 52/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 58ms/step - accuracy: 0.8654 - loss: 0.4180 - val_accuracy: 0.4596 - val_loss: 1.9008\n",
            "Epoch 53/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 58ms/step - accuracy: 0.8918 - loss: 0.4129 - val_accuracy: 0.4747 - val_loss: 1.9217\n",
            "Epoch 54/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 57ms/step - accuracy: 0.8692 - loss: 0.4109 - val_accuracy: 0.4495 - val_loss: 1.9290\n",
            "Epoch 55/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 57ms/step - accuracy: 0.8927 - loss: 0.4212 - val_accuracy: 0.4444 - val_loss: 1.9440\n",
            "Epoch 56/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 56ms/step - accuracy: 0.8707 - loss: 0.4103 - val_accuracy: 0.4495 - val_loss: 1.9733\n",
            "Epoch 57/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 57ms/step - accuracy: 0.8886 - loss: 0.3773 - val_accuracy: 0.4495 - val_loss: 1.9729\n",
            "Epoch 58/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 58ms/step - accuracy: 0.8854 - loss: 0.3873 - val_accuracy: 0.4343 - val_loss: 1.9953\n",
            "Epoch 59/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 56ms/step - accuracy: 0.8894 - loss: 0.3585 - val_accuracy: 0.4495 - val_loss: 2.0218\n",
            "Epoch 60/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 58ms/step - accuracy: 0.8627 - loss: 0.3752 - val_accuracy: 0.4495 - val_loss: 1.9721\n",
            "Epoch 61/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 58ms/step - accuracy: 0.9122 - loss: 0.2910 - val_accuracy: 0.4444 - val_loss: 1.9930\n",
            "Epoch 62/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.9271 - loss: 0.3132 - val_accuracy: 0.4444 - val_loss: 2.0317\n",
            "Epoch 63/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 57ms/step - accuracy: 0.8958 - loss: 0.3233 - val_accuracy: 0.4495 - val_loss: 2.0703\n",
            "Epoch 64/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - accuracy: 0.8935 - loss: 0.3336 - val_accuracy: 0.4394 - val_loss: 2.0809\n",
            "Epoch 65/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.9038 - loss: 0.2822 - val_accuracy: 0.4444 - val_loss: 2.0941\n",
            "Epoch 66/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 58ms/step - accuracy: 0.9236 - loss: 0.3105 - val_accuracy: 0.4444 - val_loss: 2.0880\n",
            "Epoch 67/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 57ms/step - accuracy: 0.9191 - loss: 0.2710 - val_accuracy: 0.4444 - val_loss: 2.1298\n",
            "Epoch 68/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 57ms/step - accuracy: 0.9100 - loss: 0.2986 - val_accuracy: 0.4646 - val_loss: 2.1263\n",
            "Epoch 69/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 56ms/step - accuracy: 0.9213 - loss: 0.2684 - val_accuracy: 0.4596 - val_loss: 2.0928\n",
            "Epoch 70/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.9469 - loss: 0.2194 - val_accuracy: 0.4596 - val_loss: 2.0996\n",
            "Epoch 71/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 58ms/step - accuracy: 0.9244 - loss: 0.2591 - val_accuracy: 0.4596 - val_loss: 2.1083\n",
            "Epoch 72/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 56ms/step - accuracy: 0.9408 - loss: 0.2120 - val_accuracy: 0.4697 - val_loss: 2.1638\n",
            "Epoch 73/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 56ms/step - accuracy: 0.9237 - loss: 0.2342 - val_accuracy: 0.4545 - val_loss: 2.1757\n",
            "Epoch 74/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 56ms/step - accuracy: 0.9342 - loss: 0.2301 - val_accuracy: 0.4747 - val_loss: 2.1929\n",
            "Epoch 75/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - accuracy: 0.9146 - loss: 0.2413 - val_accuracy: 0.4596 - val_loss: 2.2510\n",
            "Epoch 76/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 56ms/step - accuracy: 0.9394 - loss: 0.2128 - val_accuracy: 0.4949 - val_loss: 2.1919\n",
            "Epoch 77/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 57ms/step - accuracy: 0.9274 - loss: 0.2043 - val_accuracy: 0.4798 - val_loss: 2.2340\n",
            "Epoch 78/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - accuracy: 0.9325 - loss: 0.1963 - val_accuracy: 0.4596 - val_loss: 2.2483\n",
            "Epoch 79/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 57ms/step - accuracy: 0.9355 - loss: 0.2053 - val_accuracy: 0.4596 - val_loss: 2.2131\n",
            "Epoch 80/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 57ms/step - accuracy: 0.9250 - loss: 0.2151 - val_accuracy: 0.4646 - val_loss: 2.3009\n",
            "Epoch 81/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.9485 - loss: 0.1797 - val_accuracy: 0.4596 - val_loss: 2.3123\n",
            "Epoch 82/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 58ms/step - accuracy: 0.9496 - loss: 0.1863 - val_accuracy: 0.4848 - val_loss: 2.3360\n",
            "Epoch 83/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 0.9465 - loss: 0.1868 - val_accuracy: 0.4798 - val_loss: 2.3366\n",
            "Epoch 84/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.9304 - loss: 0.2125 - val_accuracy: 0.4394 - val_loss: 2.3304\n",
            "Epoch 85/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 56ms/step - accuracy: 0.9407 - loss: 0.1727 - val_accuracy: 0.4747 - val_loss: 2.3671\n",
            "Epoch 86/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.9591 - loss: 0.1600 - val_accuracy: 0.4697 - val_loss: 2.3302\n",
            "Epoch 87/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 57ms/step - accuracy: 0.9612 - loss: 0.1509 - val_accuracy: 0.4697 - val_loss: 2.3247\n",
            "Epoch 88/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 57ms/step - accuracy: 0.9448 - loss: 0.1890 - val_accuracy: 0.4899 - val_loss: 2.3892\n",
            "Epoch 89/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 57ms/step - accuracy: 0.9581 - loss: 0.1736 - val_accuracy: 0.4596 - val_loss: 2.3896\n",
            "Epoch 90/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 58ms/step - accuracy: 0.9447 - loss: 0.1939 - val_accuracy: 0.4697 - val_loss: 2.4098\n",
            "Epoch 91/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 57ms/step - accuracy: 0.9437 - loss: 0.1743 - val_accuracy: 0.4545 - val_loss: 2.4158\n",
            "Epoch 92/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 58ms/step - accuracy: 0.9656 - loss: 0.1354 - val_accuracy: 0.4747 - val_loss: 2.3957\n",
            "Epoch 93/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 56ms/step - accuracy: 0.9682 - loss: 0.1208 - val_accuracy: 0.4646 - val_loss: 2.4425\n",
            "Epoch 94/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 56ms/step - accuracy: 0.9453 - loss: 0.1396 - val_accuracy: 0.4495 - val_loss: 2.5150\n",
            "Epoch 95/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 57ms/step - accuracy: 0.9544 - loss: 0.1404 - val_accuracy: 0.4747 - val_loss: 2.4577\n",
            "Epoch 96/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.9540 - loss: 0.1730 - val_accuracy: 0.4545 - val_loss: 2.4415\n",
            "Epoch 97/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 56ms/step - accuracy: 0.9552 - loss: 0.1434 - val_accuracy: 0.4747 - val_loss: 2.4559\n",
            "Epoch 98/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 0.9439 - loss: 0.1566 - val_accuracy: 0.4596 - val_loss: 2.4663\n",
            "Epoch 99/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.9588 - loss: 0.1568 - val_accuracy: 0.5000 - val_loss: 2.4516\n",
            "Epoch 100/100\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 57ms/step - accuracy: 0.9720 - loss: 0.1242 - val_accuracy: 0.4697 - val_loss: 2.5190\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 478ms/step\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 480ms/step\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 478ms/step\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 483ms/step\n",
            "Ensemble validation accuracy: 0.4444\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from matplotlib import cm\n",
        "from tensorflow.keras import layers, models, optimizers\n",
        "from tensorflow.keras.applications import EfficientNetB3\n",
        "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.metrics import TopKCategoricalAccuracy\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# --- Assume df, train_df, val_df, test_df already defined as before ---\n",
        "\n",
        "batch_size  = 10\n",
        "img_height  = 256\n",
        "img_width   = 256\n",
        "num_classes = train_df['target'].nunique()\n",
        "\n",
        "# --- 1. Preprocessing functions ---\n",
        "\n",
        "def orig_preprocess(x):\n",
        "    # x is a uint8 array in [0,255], shape (H,W,3)\n",
        "    return preprocess_input(x)\n",
        "\n",
        "def gray_preprocess(x):\n",
        "    # Convert to true grayscale, then back to 3‑channel\n",
        "    gray = cv2.cvtColor(x, cv2.COLOR_RGB2GRAY)\n",
        "    gray3 = np.stack([gray, gray, gray], axis=-1)\n",
        "    return preprocess_input(gray3)\n",
        "\n",
        "def edge_preprocess(x):\n",
        "    # x may be float32 in [0,1] (if you used rescale=1./255)\n",
        "    # or float32 in [0,255] (if not). Detect and convert to uint8 0–255:\n",
        "    if x.dtype != np.uint8:\n",
        "        if x.max() <= 1.0:\n",
        "            x_uint8 = (x * 255).astype(np.uint8)\n",
        "        else:\n",
        "            x_uint8 = x.astype(np.uint8)\n",
        "    else:\n",
        "        x_uint8 = x\n",
        "\n",
        "    # Now true grayscale + Canny\n",
        "    gray = cv2.cvtColor(x_uint8, cv2.COLOR_RGB2GRAY)\n",
        "    edges = cv2.Canny(gray, 100, 200)\n",
        "\n",
        "    # Stack to 3 channels and apply EfficientNet preprocessing\n",
        "    e3 = np.stack([edges, edges, edges], axis=-1)\n",
        "    return preprocess_input(e3.astype(np.uint8))\n",
        "\n",
        "def jet_preprocess(x):\n",
        "    gray = cv2.cvtColor(x, cv2.COLOR_RGB2GRAY)\n",
        "    norm = (gray - gray.min()) / (gray.max() - gray.min() + 1e-7)\n",
        "    colored = cm.get_cmap('jet')(norm)[..., :3]   # floats [0,1]\n",
        "    colored255 = (colored * 255).astype(np.uint8)\n",
        "    return preprocess_input(colored255)\n",
        "\n",
        "# --- 2. Generator factory ---\n",
        "\n",
        "def make_generator(df, preprocess_fn, shuffle):\n",
        "    return ImageDataGenerator(preprocessing_function=preprocess_fn) \\\n",
        "        .flow_from_dataframe(\n",
        "            dataframe=df,\n",
        "            x_col='path',\n",
        "            y_col='target',\n",
        "            target_size=(img_height, img_width),\n",
        "            batch_size=batch_size,\n",
        "            class_mode='categorical',\n",
        "            shuffle=shuffle\n",
        "        )\n",
        "\n",
        "# Training generators (shuffle=True)\n",
        "orig_train = make_generator(train_df, orig_preprocess, shuffle=True)\n",
        "gray_train = make_generator(train_df, gray_preprocess, shuffle=True)\n",
        "edge_train = ImageDataGenerator(preprocessing_function=edge_preprocess) \\\n",
        "    .flow_from_dataframe(train_df, x_col='path', y_col='target',\n",
        "                         target_size=(256,256), batch_size=10, class_mode='categorical')\n",
        "jet_train  = make_generator(train_df, jet_preprocess,  shuffle=True)\n",
        "\n",
        "# Validation generators (shuffle=False for consistent ordering)\n",
        "orig_val = make_generator(val_df, orig_preprocess, shuffle=False)\n",
        "gray_val = make_generator(val_df, gray_preprocess, shuffle=False)\n",
        "edge_val   = ImageDataGenerator(preprocessing_function=edge_preprocess) \\\n",
        "    .flow_from_dataframe(val_df,   x_col='path', y_col='target',\n",
        "                         target_size=(256,256), batch_size=10, class_mode='categorical',\n",
        "                         shuffle=False)\n",
        "jet_val  = make_generator(val_df, jet_preprocess,  shuffle=False)\n",
        "\n",
        "# --- 3. Model factory (EfficientNetB3 → GAP → 256 → Dropout → 520 → Dropout → softmax) ---\n",
        "\n",
        "def build_branch_model():\n",
        "    inp = layers.Input((img_height, img_width, 3))\n",
        "    base = EfficientNetB3(\n",
        "        weights='imagenet',\n",
        "        include_top=False,\n",
        "        input_tensor=inp\n",
        "    )\n",
        "    base.trainable = False\n",
        "\n",
        "    x = layers.GlobalAveragePooling2D()(base.output)\n",
        "    x = layers.Dense(256, activation='relu')(x)\n",
        "    x = layers.Dropout(0.5)(x)\n",
        "    x = layers.Dense(520, activation='relu')(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "    out = layers.Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    m = models.Model(inp, out)\n",
        "    m.compile(\n",
        "        optimizer=optimizers.RMSprop(learning_rate=1e-4),\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=[\n",
        "            'accuracy'\n",
        "        ]\n",
        "    )\n",
        "    return m\n",
        "\n",
        "# --- 4. Instantiate branches ---\n",
        "\n",
        "model_orig = build_branch_model()\n",
        "model_gray = build_branch_model()\n",
        "model_edge = build_branch_model()\n",
        "model_jet  = build_branch_model()\n",
        "\n",
        "# --- 5. Train each branch (you should see your grayscale branch recover ~45% val‑acc) ---\n",
        "\n",
        "model_orig.fit(orig_train, validation_data=orig_val, epochs=100)\n",
        "model_gray.fit(gray_train, validation_data=gray_val, epochs=100)\n",
        "model_edge.fit(edge_train, validation_data=edge_val, epochs=100)\n",
        "model_jet.fit(jet_train,   validation_data=jet_val, epochs=100)\n",
        "\n",
        "# --- 6. Ensemble by averaging softmax probabilities ---\n",
        "\n",
        "import math\n",
        "\n",
        "def ensemble_val_accuracy(models, val_generator):\n",
        "    steps = math.ceil(val_generator.samples / val_generator.batch_size)\n",
        "    # collect each model’s predictions (shape: [N, num_classes])\n",
        "    prob_list = [m.predict(val_generator, steps=steps) for m in models]\n",
        "    avg_probs = np.mean(prob_list, axis=0)\n",
        "    y_true = val_generator.classes\n",
        "    y_pred = np.argmax(avg_probs, axis=1)\n",
        "    return np.mean(y_pred == y_true)\n",
        "\n",
        "val_acc = ensemble_val_accuracy(\n",
        "    [model_orig, model_gray, model_edge, model_jet],\n",
        "    orig_val   # any val_* generator will do, since ordering is the same\n",
        ")\n",
        "print(f\"Ensemble validation accuracy: {val_acc:.4f}\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}